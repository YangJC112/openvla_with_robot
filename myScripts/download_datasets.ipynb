{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting apache_beam\n",
      "  Using cached apache_beam-2.64.0-cp310-cp310-win_amd64.whl.metadata (9.6 kB)\n",
      "Collecting crcmod<2.0,>=1.7 (from apache_beam)\n",
      "  Using cached crcmod-1.7.tar.gz (89 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting orjson<4,>=3.9.7 (from apache_beam)\n",
      "  Using cached orjson-3.10.16-cp310-cp310-win_amd64.whl.metadata (42 kB)\n",
      "Collecting dill<0.3.2,>=0.3.1.1 (from apache_beam)\n",
      "  Using cached dill-0.3.1.1.tar.gz (151 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting cloudpickle~=2.2.1 (from apache_beam)\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting fastavro<2,>=0.23.6 (from apache_beam)\n",
      "  Using cached fastavro-1.10.0-cp310-cp310-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting fasteners<1.0,>=0.3 (from apache_beam)\n",
      "  Using cached fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 (from apache_beam)\n",
      "  Using cached grpcio-1.65.5-cp310-cp310-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting hdfs<3.0.0,>=2.1.0 (from apache_beam)\n",
      "  Using cached hdfs-2.7.3.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting httplib2<0.23.0,>=0.8 (from apache_beam)\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jsonschema<5.0.0,>=4.0.0 (from apache_beam)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache_beam)\n",
      "  Using cached jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: numpy<2.3.0,>=1.14.3 in c:\\users\\yangjc\\anaconda3\\envs\\openvla\\lib\\site-packages (from apache_beam) (1.26.4)\n",
      "Collecting objsize<0.8.0,>=0.6.1 (from apache_beam)\n",
      "  Using cached objsize-0.7.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging>=22.0 in c:\\users\\yangjc\\anaconda3\\envs\\openvla\\lib\\site-packages (from apache_beam) (25.0)\n",
      "Collecting pymongo<5.0.0,>=3.8.0 (from apache_beam)\n",
      "  Using cached pymongo-4.12.0-cp310-cp310-win_amd64.whl.metadata (22 kB)\n",
      "Collecting proto-plus<2,>=1.7.1 (from apache_beam)\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3 (from apache_beam)\n",
      "  Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting pydot<2,>=1.2.0 (from apache_beam)\n",
      "  Using cached pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in c:\\users\\yangjc\\anaconda3\\envs\\openvla\\lib\\site-packages (from apache_beam) (2.9.0.post0)\n",
      "Collecting pytz>=2018.3 (from apache_beam)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting redis<6,>=5.0.0 (from apache_beam)\n",
      "  Using cached redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: regex>=2020.6.8 in c:\\users\\yangjc\\anaconda3\\envs\\openvla\\lib\\site-packages (from apache_beam) (2024.11.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in c:\\users\\yangjc\\anaconda3\\envs\\openvla\\lib\\site-packages (from apache_beam) (2.32.3)\n",
      "Collecting sortedcontainers>=2.4.0 (from apache_beam)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in c:\\users\\yangjc\\anaconda3\\envs\\openvla\\lib\\site-packages (from apache_beam) (4.12.2)\n",
      "Collecting zstandard<1,>=0.18.0 (from apache_beam)\n",
      "  Using cached zstandard-0.23.0-cp310-cp310-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=3.12 in c:\\users\\yangjc\\anaconda3\\envs\\openvla\\lib\\site-packages (from apache_beam) (6.0.2)\n",
      "Collecting pyarrow<17.0.0,>=3.0.0 (from apache_beam)\n",
      "  Using cached pyarrow-16.1.0-cp310-cp310-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting pyarrow-hotfix<1 (from apache_beam)\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache_beam)\n",
      "  Using cached docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\yangjc\\anaconda3\\envs\\openvla\\lib\\site-packages (from hdfs<3.0.0,>=2.1.0->apache_beam) (1.17.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\yangjc\\anaconda3\\envs\\openvla\\lib\\site-packages (from httplib2<0.23.0,>=0.8->apache_beam) (3.2.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\yangjc\\anaconda3\\envs\\openvla\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->apache_beam) (25.3.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.0.0->apache_beam)\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.0.0->apache_beam)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.0.0->apache_beam)\n",
      "  Using cached rpds_py-0.24.0-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache_beam)\n",
      "  Using cached dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting async-timeout>=4.0.3 (from redis<6,>=5.0.0->apache_beam)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yangjc\\anaconda3\\envs\\openvla\\lib\\site-packages (from requests<3.0.0,>=2.24.0->apache_beam) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yangjc\\anaconda3\\envs\\openvla\\lib\\site-packages (from requests<3.0.0,>=2.24.0->apache_beam) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yangjc\\anaconda3\\envs\\openvla\\lib\\site-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yangjc\\anaconda3\\envs\\openvla\\lib\\site-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2025.1.31)\n",
      "Using cached apache_beam-2.64.0-cp310-cp310-win_amd64.whl (5.5 MB)\n",
      "Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Using cached fastavro-1.10.0-cp310-cp310-win_amd64.whl (497 kB)\n",
      "Using cached fasteners-0.19-py3-none-any.whl (18 kB)\n",
      "Using cached grpcio-1.65.5-cp310-cp310-win_amd64.whl (4.1 MB)\n",
      "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Using cached jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached objsize-0.7.1-py3-none-any.whl (11 kB)\n",
      "Using cached orjson-3.10.16-cp310-cp310-win_amd64.whl (133 kB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading pyarrow-16.1.0-cp310-cp310-win_amd64.whl (25.9 MB)\n",
      "   ---------------------------------------- 0.0/25.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/25.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/25.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/25.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/25.9 MB 985.5 kB/s eta 0:00:26\n",
      "   - -------------------------------------- 0.8/25.9 MB 931.2 kB/s eta 0:00:27\n",
      "   -- ------------------------------------- 1.6/25.9 MB 1.8 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 2.9/25.9 MB 2.7 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 4.2/25.9 MB 3.4 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 4.5/25.9 MB 3.3 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 6.3/25.9 MB 3.7 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 7.1/25.9 MB 3.8 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 8.4/25.9 MB 4.1 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 9.7/25.9 MB 4.3 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 11.0/25.9 MB 4.5 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 12.1/25.9 MB 4.5 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 13.4/25.9 MB 4.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 14.7/25.9 MB 4.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 16.0/25.9 MB 4.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 17.3/25.9 MB 5.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.9/25.9 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 20.4/25.9 MB 5.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 21.8/25.9 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.1/25.9 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.6/25.9 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.9/25.9 MB 5.5 MB/s eta 0:00:00\n",
      "Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Using cached pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Using cached pymongo-4.12.0-cp310-cp310-win_amd64.whl (795 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached redis-5.2.1-py3-none-any.whl (261 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Using cached zstandard-0.23.0-cp310-cp310-win_amd64.whl (495 kB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Using cached rpds_py-0.24.0-cp310-cp310-win_amd64.whl (234 kB)\n",
      "Building wheels for collected packages: crcmod, dill, hdfs, docopt\n",
      "  Building wheel for crcmod (setup.py): started\n",
      "  Building wheel for crcmod (setup.py): finished with status 'done'\n",
      "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-win_amd64.whl size=25424 sha256=6647e54f0efca53bbe18cb5c4d1380359a69475e396829f6ee2820569decec02\n",
      "  Stored in directory: c:\\users\\yangjc\\appdata\\local\\pip\\cache\\wheels\\85\\4c\\07\\72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
      "  Building wheel for dill (setup.py): started\n",
      "  Building wheel for dill (setup.py): finished with status 'done'\n",
      "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78720 sha256=9681a1e9a9f705b7047b97f66f05ac1c4e4ee09133996182fa133b5044e6a22e\n",
      "  Stored in directory: c:\\users\\yangjc\\appdata\\local\\pip\\cache\\wheels\\ea\\e2\\86\\64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
      "  Building wheel for hdfs (setup.py): started\n",
      "  Building wheel for hdfs (setup.py): finished with status 'done'\n",
      "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34411 sha256=b2f99cf39c11093e7e0ce3fd23a8cdebdb26099ca2991a98461c36c6874c37b7\n",
      "  Stored in directory: c:\\users\\yangjc\\appdata\\local\\pip\\cache\\wheels\\e5\\8d\\b6\\99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13822 sha256=090865e0fae09deb7e974462cb53f4318ef0b28750edb1cb6498e034779bce5d\n",
      "  Stored in directory: c:\\users\\yangjc\\appdata\\local\\pip\\cache\\wheels\\fc\\ab\\d4\\5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "Successfully built crcmod dill hdfs docopt\n",
      "Installing collected packages: sortedcontainers, pytz, docopt, crcmod, zstandard, rpds-py, pydot, pyarrow-hotfix, pyarrow, protobuf, orjson, objsize, jsonpickle, httplib2, grpcio, fasteners, fastavro, dnspython, dill, cloudpickle, async-timeout, referencing, redis, pymongo, proto-plus, hdfs, jsonschema-specifications, jsonschema, apache_beam\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.21.12\n",
      "    Uninstalling protobuf-4.21.12:\n",
      "      Successfully uninstalled protobuf-4.21.12\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.71.0\n",
      "    Uninstalling grpcio-1.71.0:\n",
      "      Successfully uninstalled grpcio-1.71.0\n",
      "Successfully installed apache_beam-2.64.0 async-timeout-5.0.1 cloudpickle-2.2.1 crcmod-1.7 dill-0.3.1.1 dnspython-2.7.0 docopt-0.6.2 fastavro-1.10.0 fasteners-0.19 grpcio-1.65.5 hdfs-2.7.3 httplib2-0.22.0 jsonpickle-3.4.2 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 objsize-0.7.1 orjson-3.10.16 proto-plus-1.26.1 protobuf-5.29.4 pyarrow-16.1.0 pyarrow-hotfix-0.6 pydot-1.4.2 pymongo-4.12.0 pytz-2025.2 redis-5.2.1 referencing-0.36.2 rpds-py-0.24.0 sortedcontainers-2.4.0 zstandard-0.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "openvla 0.0.3 requires torch==2.2.0, but you have torch 2.5.1 which is incompatible.\n",
      "openvla 0.0.3 requires torchaudio==2.2.0, but you have torchaudio 2.5.1 which is incompatible.\n",
      "openvla 0.0.3 requires torchvision==0.17.0, but you have torchvision 0.20.1 which is incompatible.\n",
      "tensorflow-intel 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.4 which is incompatible.\n",
      "tensorflow-metadata 1.17.1 requires protobuf<4.22,>=4.21.6; python_version < \"3.11\", but you have protobuf 5.29.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# !pip install tfds-nightly   # to get most up-to-date registered datasets\n",
    "# !pip install apache_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 3 datasets to ~/tensorflow_datasets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "DatasetNotFoundError",
     "evalue": "Dataset austin_buds_dataset_converted_externally_to_rlds not found.\nAvailable datasets:\n\t- abstract_reasoning\n\t- accentdb\n\t- aeslc\n\t- aflw2k3d\n\t- ag_news_subset\n\t- ai2_arc\n\t- ai2_arc_with_ir\n\t- amazon_us_reviews\n\t- anli\n\t- answer_equivalence\n\t- arc\n\t- asqa\n\t- asset\n\t- assin2\n\t- bair_robot_pushing_small\n\t- bccd\n\t- beans\n\t- bee_dataset\n\t- beir\n\t- big_patent\n\t- bigearthnet\n\t- billsum\n\t- binarized_mnist\n\t- binary_alpha_digits\n\t- ble_wind_field\n\t- blimp\n\t- booksum\n\t- bool_q\n\t- bucc\n\t- c4\n\t- c4_wsrs\n\t- caltech101\n\t- caltech_birds2010\n\t- caltech_birds2011\n\t- cardiotox\n\t- cars196\n\t- cassava\n\t- cats_vs_dogs\n\t- celeb_a\n\t- celeb_a_hq\n\t- cfq\n\t- cherry_blossoms\n\t- chexpert\n\t- cifar10\n\t- cifar100\n\t- cifar100_n\n\t- cifar10_1\n\t- cifar10_corrupted\n\t- cifar10_n\n\t- citrus_leaves\n\t- cityscapes\n\t- civil_comments\n\t- clevr\n\t- clic\n\t- clinc_oos\n\t- cmaterdb\n\t- cnn_dailymail\n\t- coco\n\t- coco_captions\n\t- coil100\n\t- colorectal_histology\n\t- colorectal_histology_large\n\t- common_voice\n\t- conll2002\n\t- conll2003\n\t- controlled_noisy_web_labels\n\t- coqa\n\t- cos_e\n\t- cosmos_qa\n\t- covid19\n\t- covid19sum\n\t- crema_d\n\t- criteo\n\t- cs_restaurants\n\t- curated_breast_imaging_ddsm\n\t- cycle_gan\n\t- d4rl_adroit_door\n\t- d4rl_adroit_hammer\n\t- d4rl_adroit_pen\n\t- d4rl_adroit_relocate\n\t- d4rl_antmaze\n\t- d4rl_mujoco_ant\n\t- d4rl_mujoco_halfcheetah\n\t- d4rl_mujoco_hopper\n\t- d4rl_mujoco_walker2d\n\t- dart\n\t- davis\n\t- deep1b\n\t- deep_weeds\n\t- definite_pronoun_resolution\n\t- dementiabank\n\t- diabetic_retinopathy_detection\n\t- diamonds\n\t- div2k\n\t- dmlab\n\t- doc_nli\n\t- dolphin_number_word\n\t- domainnet\n\t- downsampled_imagenet\n\t- drop\n\t- dsprites\n\t- dtd\n\t- duke_ultrasound\n\t- e2e_cleaned\n\t- efron_morris75\n\t- emnist\n\t- eraser_multi_rc\n\t- esnli\n\t- eurosat\n\t- fashion_mnist\n\t- flic\n\t- flores\n\t- food101\n\t- forest_fires\n\t- fuss\n\t- gap\n\t- geirhos_conflict_stimuli\n\t- gem\n\t- genomics_ood\n\t- german_credit_numeric\n\t- gigaword\n\t- glove100_angular\n\t- glue\n\t- goemotions\n\t- gov_report\n\t- gpt3\n\t- gref\n\t- groove\n\t- grounded_scan\n\t- gsm8k\n\t- gtzan\n\t- gtzan_music_speech\n\t- hellaswag\n\t- higgs\n\t- hillstrom\n\t- horses_or_humans\n\t- howell\n\t- i_naturalist2017\n\t- i_naturalist2018\n\t- i_naturalist2021\n\t- imagenet2012\n\t- imagenet2012_corrupted\n\t- imagenet2012_fewshot\n\t- imagenet2012_multilabel\n\t- imagenet2012_real\n\t- imagenet2012_subset\n\t- imagenet_a\n\t- imagenet_lt\n\t- imagenet_pi\n\t- imagenet_r\n\t- imagenet_resized\n\t- imagenet_sketch\n\t- imagenet_v2\n\t- imagenette\n\t- imagewang\n\t- imdb_reviews\n\t- irc_disentanglement\n\t- iris\n\t- istella\n\t- kddcup99\n\t- kitti\n\t- kmnist\n\t- laion400m\n\t- lambada\n\t- lfw\n\t- librispeech\n\t- librispeech_lm\n\t- libritts\n\t- ljspeech\n\t- lm1b\n\t- locomotion\n\t- lost_and_found\n\t- lsun\n\t- lvis\n\t- malaria\n\t- math_dataset\n\t- math_qa\n\t- mctaco\n\t- media_sum\n\t- mlqa\n\t- mnist\n\t- mnist_corrupted\n\t- movie_lens\n\t- movie_rationales\n\t- movielens\n\t- moving_mnist\n\t- mrqa\n\t- mslr_web\n\t- mt_opt\n\t- mtnt\n\t- multi_news\n\t- multi_nli\n\t- multi_nli_mismatch\n\t- natural_instructions\n\t- natural_questions\n\t- natural_questions_open\n\t- newsroom\n\t- nsynth\n\t- nyu_depth_v2\n\t- ogbg_molpcba\n\t- omniglot\n\t- open_images_challenge2019_detection\n\t- open_images_v4\n\t- openbookqa\n\t- opinion_abstracts\n\t- opinosis\n\t- opus\n\t- oxford_flowers102\n\t- oxford_iiit_pet\n\t- para_crawl\n\t- pass\n\t- patch_camelyon\n\t- paws_wiki\n\t- paws_x_wiki\n\t- penguins\n\t- pet_finder\n\t- pg19\n\t- piqa\n\t- places365_small\n\t- placesfull\n\t- plant_leaves\n\t- plant_village\n\t- plantae_k\n\t- protein_net\n\t- q_re_cc\n\t- qa4mre\n\t- qasc\n\t- quac\n\t- quality\n\t- quickdraw_bitmap\n\t- race\n\t- radon\n\t- reddit\n\t- reddit_disentanglement\n\t- reddit_tifu\n\t- ref_coco\n\t- resisc45\n\t- rlu_atari\n\t- rlu_atari_checkpoints\n\t- rlu_atari_checkpoints_ordered\n\t- rlu_control_suite\n\t- rlu_dmlab_explore_object_rewards_few\n\t- rlu_dmlab_explore_object_rewards_many\n\t- rlu_dmlab_rooms_select_nonmatching_object\n\t- rlu_dmlab_rooms_watermaze\n\t- rlu_dmlab_seekavoid_arena01\n\t- rlu_locomotion\n\t- rlu_rwrl\n\t- robomimic_mg\n\t- robomimic_mh\n\t- robomimic_ph\n\t- robonet\n\t- robosuite_panda_pick_place_can\n\t- rock_paper_scissors\n\t- rock_you\n\t- s3o4d\n\t- salient_span_wikipedia\n\t- samsum\n\t- savee\n\t- scan\n\t- scene_parse150\n\t- schema_guided_dialogue\n\t- sci_tail\n\t- scicite\n\t- scientific_papers\n\t- scrolls\n\t- sentiment140\n\t- shapes3d\n\t- sift1m\n\t- simpte\n\t- siscore\n\t- smallnorb\n\t- smartwatch_gestures\n\t- snli\n\t- so2sat\n\t- speech_commands\n\t- spoken_digit\n\t- squad\n\t- squad_question_generation\n\t- stanford_dogs\n\t- stanford_online_products\n\t- star_cfq\n\t- starcraft_video\n\t- stl10\n\t- story_cloze\n\t- summscreen\n\t- sun397\n\t- super_glue\n\t- svhn_cropped\n\t- symmetric_solids\n\t- tao\n\t- tatoeba\n\t- ted_hrlr_translate\n\t- ted_multi_translate\n\t- tedlium\n\t- tf_flowers\n\t- the300w_lp\n\t- tiny_shakespeare\n\t- titanic\n\t- trec\n\t- trivia_qa\n\t- tydi_qa\n\t- uc_merced\n\t- ucf101\n\t- unified_qa\n\t- universal_dependencies\n\t- unnatural_instructions\n\t- user_libri_audio\n\t- user_libri_text\n\t- vctk\n\t- visual_domain_decathlon\n\t- voc\n\t- voxceleb\n\t- voxforge\n\t- waymo_open_dataset\n\t- web_graph\n\t- web_nlg\n\t- web_questions\n\t- webvid\n\t- wider_face\n\t- wiki40b\n\t- wiki_auto\n\t- wiki_bio\n\t- wiki_dialog\n\t- wiki_table_questions\n\t- wiki_table_text\n\t- wikiann\n\t- wikihow\n\t- wikipedia\n\t- wikipedia_toxicity_subtypes\n\t- wine_quality\n\t- winogrande\n\t- wit\n\t- wit_kaggle\n\t- wmt13_translate\n\t- wmt14_translate\n\t- wmt15_translate\n\t- wmt16_translate\n\t- wmt17_translate\n\t- wmt18_translate\n\t- wmt19_translate\n\t- wmt_t2t_translate\n\t- wmt_translate\n\t- wordnet\n\t- wsc273\n\t- xnli\n\t- xquad\n\t- xsum\n\t- xtreme_pawsx\n\t- xtreme_pos\n\t- xtreme_s\n\t- xtreme_xnli\n\t- yahoo_ltrc\n\t- yelp_polarity_reviews\n\t- yes_no\n\t- youtube_vis\n\nCheck that:\n    - if dataset was added recently, it may only be available\n      in `tfds-nightly`\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - the module defining the dataset class is imported\n\nThe builder directory ~\\tensorflow_datasets\\austin_buds_dataset_converted_externally_to_rlds doesn't contain any versions.\nNo builder could be found in the directory: ~/tensorflow_datasets for the builder: austin_buds_dataset_converted_externally_to_rlds.\nNo registered data_dirs were found in:\n\t- ~/tensorflow_datasets\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDatasetNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(DATASET_NAMES)\u001b[39m}\u001b[39;00m\u001b[39m datasets to \u001b[39m\u001b[39m{\u001b[39;00mDOWNLOAD_DIR\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m dataset_name \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(DATASET_NAMES):\n\u001b[1;32m---> 11\u001b[0m   _ \u001b[39m=\u001b[39m tfds\u001b[39m.\u001b[39;49mload(dataset_name, data_dir\u001b[39m=\u001b[39;49mDOWNLOAD_DIR)\n",
      "File \u001b[1;32mc:\\Users\\YangJC\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:169\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[1;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_call()\n\u001b[0;32m    168\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m   \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    170\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    171\u001b[0m   metadata\u001b[39m.\u001b[39mmark_error()\n",
      "File \u001b[1;32mc:\\Users\\YangJC\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow_datasets\\core\\load.py:634\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[39m@tfds_logging\u001b[39m\u001b[39m.\u001b[39mload()\n\u001b[0;32m    503\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[0;32m    504\u001b[0m     name: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m ):\n\u001b[0;32m    520\u001b[0m   \u001b[39m# pylint: disable=line-too-long\u001b[39;00m\n\u001b[0;32m    521\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Loads the named dataset into a `tf.data.Dataset`.\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \n\u001b[0;32m    523\u001b[0m \u001b[39m  `tfds.load` is a convenience method that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[39m      Split-specific information is available in `ds_info.splits`.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m   dbuilder \u001b[39m=\u001b[39m _fetch_builder(\n\u001b[0;32m    635\u001b[0m       name,\n\u001b[0;32m    636\u001b[0m       data_dir,\n\u001b[0;32m    637\u001b[0m       builder_kwargs,\n\u001b[0;32m    638\u001b[0m       try_gcs,\n\u001b[0;32m    639\u001b[0m   )\n\u001b[0;32m    640\u001b[0m   _download_and_prepare_builder(dbuilder, download, download_and_prepare_kwargs)\n\u001b[0;32m    642\u001b[0m   \u001b[39mif\u001b[39;00m as_dataset_kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\YangJC\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow_datasets\\core\\load.py:489\u001b[0m, in \u001b[0;36m_fetch_builder\u001b[1;34m(name, data_dir, builder_kwargs, try_gcs)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[39mif\u001b[39;00m builder_kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    487\u001b[0m   builder_kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 489\u001b[0m \u001b[39mreturn\u001b[39;00m builder(name, data_dir\u001b[39m=\u001b[39;49mdata_dir, try_gcs\u001b[39m=\u001b[39;49mtry_gcs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbuilder_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\YangJC\\anaconda3\\envs\\nlp\\lib\\contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[0;32m     74\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 75\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[1;32mc:\\Users\\YangJC\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:169\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[1;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_call()\n\u001b[0;32m    168\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m   \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    170\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    171\u001b[0m   metadata\u001b[39m.\u001b[39mmark_error()\n",
      "File \u001b[1;32mc:\\Users\\YangJC\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow_datasets\\core\\load.py:215\u001b[0m, in \u001b[0;36mbuilder\u001b[1;34m(name, try_gcs, **builder_kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbuilder_kwargs)  \u001b[39m# pytype: disable=not-instantiable\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \u001b[39m# If neither the code nor the files are found, raise DatasetNotFoundError\u001b[39;00m\n\u001b[1;32m--> 215\u001b[0m \u001b[39mraise\u001b[39;00m not_found_error\n",
      "File \u001b[1;32mc:\\Users\\YangJC\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow_datasets\\core\\load.py:196\u001b[0m, in \u001b[0;36mbuilder\u001b[1;34m(name, try_gcs, **builder_kwargs)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39m# First check whether we can find the corresponding dataset builder code\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m   \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m builder_cls(\u001b[39mstr\u001b[39;49m(name))\n\u001b[0;32m    197\u001b[0m \u001b[39mexcept\u001b[39;00m registered\u001b[39m.\u001b[39mDatasetNotFoundError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m   \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# Class not found\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\YangJC\\anaconda3\\envs\\nlp\\lib\\contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[0;32m     74\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 75\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[1;32mc:\\Users\\YangJC\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow_datasets\\core\\load.py:121\u001b[0m, in \u001b[0;36mbuilder_cls\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 121\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m registered\u001b[39m.\u001b[39;49mimported_builder_cls(\u001b[39mstr\u001b[39;49m(ds_name))\n\u001b[0;32m    122\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m typing\u001b[39m.\u001b[39mcast(Type[dataset_builder\u001b[39m.\u001b[39mDatasetBuilder], \u001b[39mcls\u001b[39m)\n\u001b[0;32m    123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\YangJC\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py:301\u001b[0m, in \u001b[0;36mimported_builder_cls\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    298\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDataset \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m is an abstract class.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    300\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _DATASET_REGISTRY:\n\u001b[1;32m--> 301\u001b[0m   \u001b[39mraise\u001b[39;00m DatasetNotFoundError(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDataset \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m not found.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    303\u001b[0m builder_cls \u001b[39m=\u001b[39m _DATASET_REGISTRY[name]\n\u001b[0;32m    304\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_builder_available(builder_cls):\n",
      "\u001b[1;31mDatasetNotFoundError\u001b[0m: Dataset austin_buds_dataset_converted_externally_to_rlds not found.\nAvailable datasets:\n\t- abstract_reasoning\n\t- accentdb\n\t- aeslc\n\t- aflw2k3d\n\t- ag_news_subset\n\t- ai2_arc\n\t- ai2_arc_with_ir\n\t- amazon_us_reviews\n\t- anli\n\t- answer_equivalence\n\t- arc\n\t- asqa\n\t- asset\n\t- assin2\n\t- bair_robot_pushing_small\n\t- bccd\n\t- beans\n\t- bee_dataset\n\t- beir\n\t- big_patent\n\t- bigearthnet\n\t- billsum\n\t- binarized_mnist\n\t- binary_alpha_digits\n\t- ble_wind_field\n\t- blimp\n\t- booksum\n\t- bool_q\n\t- bucc\n\t- c4\n\t- c4_wsrs\n\t- caltech101\n\t- caltech_birds2010\n\t- caltech_birds2011\n\t- cardiotox\n\t- cars196\n\t- cassava\n\t- cats_vs_dogs\n\t- celeb_a\n\t- celeb_a_hq\n\t- cfq\n\t- cherry_blossoms\n\t- chexpert\n\t- cifar10\n\t- cifar100\n\t- cifar100_n\n\t- cifar10_1\n\t- cifar10_corrupted\n\t- cifar10_n\n\t- citrus_leaves\n\t- cityscapes\n\t- civil_comments\n\t- clevr\n\t- clic\n\t- clinc_oos\n\t- cmaterdb\n\t- cnn_dailymail\n\t- coco\n\t- coco_captions\n\t- coil100\n\t- colorectal_histology\n\t- colorectal_histology_large\n\t- common_voice\n\t- conll2002\n\t- conll2003\n\t- controlled_noisy_web_labels\n\t- coqa\n\t- cos_e\n\t- cosmos_qa\n\t- covid19\n\t- covid19sum\n\t- crema_d\n\t- criteo\n\t- cs_restaurants\n\t- curated_breast_imaging_ddsm\n\t- cycle_gan\n\t- d4rl_adroit_door\n\t- d4rl_adroit_hammer\n\t- d4rl_adroit_pen\n\t- d4rl_adroit_relocate\n\t- d4rl_antmaze\n\t- d4rl_mujoco_ant\n\t- d4rl_mujoco_halfcheetah\n\t- d4rl_mujoco_hopper\n\t- d4rl_mujoco_walker2d\n\t- dart\n\t- davis\n\t- deep1b\n\t- deep_weeds\n\t- definite_pronoun_resolution\n\t- dementiabank\n\t- diabetic_retinopathy_detection\n\t- diamonds\n\t- div2k\n\t- dmlab\n\t- doc_nli\n\t- dolphin_number_word\n\t- domainnet\n\t- downsampled_imagenet\n\t- drop\n\t- dsprites\n\t- dtd\n\t- duke_ultrasound\n\t- e2e_cleaned\n\t- efron_morris75\n\t- emnist\n\t- eraser_multi_rc\n\t- esnli\n\t- eurosat\n\t- fashion_mnist\n\t- flic\n\t- flores\n\t- food101\n\t- forest_fires\n\t- fuss\n\t- gap\n\t- geirhos_conflict_stimuli\n\t- gem\n\t- genomics_ood\n\t- german_credit_numeric\n\t- gigaword\n\t- glove100_angular\n\t- glue\n\t- goemotions\n\t- gov_report\n\t- gpt3\n\t- gref\n\t- groove\n\t- grounded_scan\n\t- gsm8k\n\t- gtzan\n\t- gtzan_music_speech\n\t- hellaswag\n\t- higgs\n\t- hillstrom\n\t- horses_or_humans\n\t- howell\n\t- i_naturalist2017\n\t- i_naturalist2018\n\t- i_naturalist2021\n\t- imagenet2012\n\t- imagenet2012_corrupted\n\t- imagenet2012_fewshot\n\t- imagenet2012_multilabel\n\t- imagenet2012_real\n\t- imagenet2012_subset\n\t- imagenet_a\n\t- imagenet_lt\n\t- imagenet_pi\n\t- imagenet_r\n\t- imagenet_resized\n\t- imagenet_sketch\n\t- imagenet_v2\n\t- imagenette\n\t- imagewang\n\t- imdb_reviews\n\t- irc_disentanglement\n\t- iris\n\t- istella\n\t- kddcup99\n\t- kitti\n\t- kmnist\n\t- laion400m\n\t- lambada\n\t- lfw\n\t- librispeech\n\t- librispeech_lm\n\t- libritts\n\t- ljspeech\n\t- lm1b\n\t- locomotion\n\t- lost_and_found\n\t- lsun\n\t- lvis\n\t- malaria\n\t- math_dataset\n\t- math_qa\n\t- mctaco\n\t- media_sum\n\t- mlqa\n\t- mnist\n\t- mnist_corrupted\n\t- movie_lens\n\t- movie_rationales\n\t- movielens\n\t- moving_mnist\n\t- mrqa\n\t- mslr_web\n\t- mt_opt\n\t- mtnt\n\t- multi_news\n\t- multi_nli\n\t- multi_nli_mismatch\n\t- natural_instructions\n\t- natural_questions\n\t- natural_questions_open\n\t- newsroom\n\t- nsynth\n\t- nyu_depth_v2\n\t- ogbg_molpcba\n\t- omniglot\n\t- open_images_challenge2019_detection\n\t- open_images_v4\n\t- openbookqa\n\t- opinion_abstracts\n\t- opinosis\n\t- opus\n\t- oxford_flowers102\n\t- oxford_iiit_pet\n\t- para_crawl\n\t- pass\n\t- patch_camelyon\n\t- paws_wiki\n\t- paws_x_wiki\n\t- penguins\n\t- pet_finder\n\t- pg19\n\t- piqa\n\t- places365_small\n\t- placesfull\n\t- plant_leaves\n\t- plant_village\n\t- plantae_k\n\t- protein_net\n\t- q_re_cc\n\t- qa4mre\n\t- qasc\n\t- quac\n\t- quality\n\t- quickdraw_bitmap\n\t- race\n\t- radon\n\t- reddit\n\t- reddit_disentanglement\n\t- reddit_tifu\n\t- ref_coco\n\t- resisc45\n\t- rlu_atari\n\t- rlu_atari_checkpoints\n\t- rlu_atari_checkpoints_ordered\n\t- rlu_control_suite\n\t- rlu_dmlab_explore_object_rewards_few\n\t- rlu_dmlab_explore_object_rewards_many\n\t- rlu_dmlab_rooms_select_nonmatching_object\n\t- rlu_dmlab_rooms_watermaze\n\t- rlu_dmlab_seekavoid_arena01\n\t- rlu_locomotion\n\t- rlu_rwrl\n\t- robomimic_mg\n\t- robomimic_mh\n\t- robomimic_ph\n\t- robonet\n\t- robosuite_panda_pick_place_can\n\t- rock_paper_scissors\n\t- rock_you\n\t- s3o4d\n\t- salient_span_wikipedia\n\t- samsum\n\t- savee\n\t- scan\n\t- scene_parse150\n\t- schema_guided_dialogue\n\t- sci_tail\n\t- scicite\n\t- scientific_papers\n\t- scrolls\n\t- sentiment140\n\t- shapes3d\n\t- sift1m\n\t- simpte\n\t- siscore\n\t- smallnorb\n\t- smartwatch_gestures\n\t- snli\n\t- so2sat\n\t- speech_commands\n\t- spoken_digit\n\t- squad\n\t- squad_question_generation\n\t- stanford_dogs\n\t- stanford_online_products\n\t- star_cfq\n\t- starcraft_video\n\t- stl10\n\t- story_cloze\n\t- summscreen\n\t- sun397\n\t- super_glue\n\t- svhn_cropped\n\t- symmetric_solids\n\t- tao\n\t- tatoeba\n\t- ted_hrlr_translate\n\t- ted_multi_translate\n\t- tedlium\n\t- tf_flowers\n\t- the300w_lp\n\t- tiny_shakespeare\n\t- titanic\n\t- trec\n\t- trivia_qa\n\t- tydi_qa\n\t- uc_merced\n\t- ucf101\n\t- unified_qa\n\t- universal_dependencies\n\t- unnatural_instructions\n\t- user_libri_audio\n\t- user_libri_text\n\t- vctk\n\t- visual_domain_decathlon\n\t- voc\n\t- voxceleb\n\t- voxforge\n\t- waymo_open_dataset\n\t- web_graph\n\t- web_nlg\n\t- web_questions\n\t- webvid\n\t- wider_face\n\t- wiki40b\n\t- wiki_auto\n\t- wiki_bio\n\t- wiki_dialog\n\t- wiki_table_questions\n\t- wiki_table_text\n\t- wikiann\n\t- wikihow\n\t- wikipedia\n\t- wikipedia_toxicity_subtypes\n\t- wine_quality\n\t- winogrande\n\t- wit\n\t- wit_kaggle\n\t- wmt13_translate\n\t- wmt14_translate\n\t- wmt15_translate\n\t- wmt16_translate\n\t- wmt17_translate\n\t- wmt18_translate\n\t- wmt19_translate\n\t- wmt_t2t_translate\n\t- wmt_translate\n\t- wordnet\n\t- wsc273\n\t- xnli\n\t- xquad\n\t- xsum\n\t- xtreme_pawsx\n\t- xtreme_pos\n\t- xtreme_s\n\t- xtreme_xnli\n\t- yahoo_ltrc\n\t- yelp_polarity_reviews\n\t- yes_no\n\t- youtube_vis\n\nCheck that:\n    - if dataset was added recently, it may only be available\n      in `tfds-nightly`\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - the module defining the dataset class is imported\n\nThe builder directory ~\\tensorflow_datasets\\austin_buds_dataset_converted_externally_to_rlds doesn't contain any versions.\nNo builder could be found in the directory: ~/tensorflow_datasets for the builder: austin_buds_dataset_converted_externally_to_rlds.\nNo registered data_dirs were found in:\n\t- ~/tensorflow_datasets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tqdm\n",
    "\n",
    "# optionally replace the DATASET_NAMES below with the list of filtered datasets from the google sheet\n",
    "# DATASET_NAMES = ['fractal20220817_data', 'kuka', 'bridge', 'taco_play', 'jaco_play', 'berkeley_cable_routing', 'roboturk', 'nyu_door_opening_surprising_effectiveness', 'viola', 'berkeley_autolab_ur5', 'toto', 'language_table', 'columbia_cairlab_pusht_real', 'stanford_kuka_multimodal_dataset_converted_externally_to_rlds', 'nyu_rot_dataset_converted_externally_to_rlds', 'stanford_hydra_dataset_converted_externally_to_rlds', 'austin_buds_dataset_converted_externally_to_rlds', 'nyu_franka_play_dataset_converted_externally_to_rlds', 'maniskill_dataset_converted_externally_to_rlds', 'furniture_bench_dataset_converted_externally_to_rlds', 'cmu_franka_exploration_dataset_converted_externally_to_rlds', 'ucsd_kitchen_dataset_converted_externally_to_rlds', 'ucsd_pick_and_place_dataset_converted_externally_to_rlds', 'austin_sailor_dataset_converted_externally_to_rlds', 'austin_sirius_dataset_converted_externally_to_rlds', 'bc_z', 'usc_cloth_sim_converted_externally_to_rlds', 'utokyo_pr2_opening_fridge_converted_externally_to_rlds', 'utokyo_pr2_tabletop_manipulation_converted_externally_to_rlds', 'utokyo_saytap_converted_externally_to_rlds', 'utokyo_xarm_pick_and_place_converted_externally_to_rlds', 'utokyo_xarm_bimanual_converted_externally_to_rlds', 'robo_net', 'berkeley_mvp_converted_externally_to_rlds', 'berkeley_rpt_converted_externally_to_rlds', 'kaist_nonprehensile_converted_externally_to_rlds', 'stanford_mask_vit_converted_externally_to_rlds', 'tokyo_u_lsmo_converted_externally_to_rlds', 'dlr_sara_pour_converted_externally_to_rlds', 'dlr_sara_grid_clamp_converted_externally_to_rlds', 'dlr_edan_shared_control_converted_externally_to_rlds', 'asu_table_top_converted_externally_to_rlds', 'stanford_robocook_converted_externally_to_rlds', 'eth_agent_affordances', 'imperialcollege_sawyer_wrist_cam', 'iamlab_cmu_pickup_insert_converted_externally_to_rlds', 'uiuc_d3field', 'utaustin_mutex', 'berkeley_fanuc_manipulation', 'cmu_food_manipulation', 'cmu_play_fusion', 'cmu_stretch', 'berkeley_gnm_recon', 'berkeley_gnm_cory_hall', 'berkeley_gnm_sac_son']\n",
    "DATASET_NAMES = ['austin_buds_dataset_converted_externally_to_rlds', 'cmu_franka_exploration_dataset_converted_externally_to_rlds', 'utokyo_pr2_opening_fridge_converted_externally_to_rlds']\n",
    "DOWNLOAD_DIR = '~/tensorflow_datasets'\n",
    "\n",
    "print(f\"Downloading {len(DATASET_NAMES)} datasets to {DOWNLOAD_DIR}.\")\n",
    "for dataset_name in tqdm.tqdm(DATASET_NAMES):\n",
    "  _ = tfds.load(dataset_name, data_dir=DOWNLOAD_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
