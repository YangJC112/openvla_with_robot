{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26f39d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chuangzhi/zhq/miniconda3/envs/openvla/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-20 15:18:50.320479: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-20 15:18:50.320573: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-20 15:18:50.321782: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-20 15:18:50.328471: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-20 15:18:51.049972: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "finetune.py\n",
    "\n",
    "Simple script for parameter-efficient fine-tuning of OpenVLA models loaded through the HuggingFace AutoClasses, using\n",
    "HuggingFace PEFT library for low-rank adaptation (LoRA).\n",
    "\n",
    "Notes & Benchmarks:\n",
    "    - Requires PEFT (`pip install peft==0.11.1`)\n",
    "    - LoRA fine-tuning (see parameters below -- no quantization, LoRA rank = 32, target_modules = all-linear):\n",
    "        + One 48 GB GPU can fit a Batch Size of 12\n",
    "        + One 80 GB GPU can fit a Batch Size of 24\n",
    "\n",
    "Run with:\n",
    "    - [Single Node Multi-GPU (= $K) ]: torchrun --standalone --nnodes 1 --nproc-per-node $K vla-scripts/finetune.py\n",
    "    - [Override Config Values]: torchrun --standalone --nnodes 1 --nproc-per-node $K vla-scripts/finetune.py \\\n",
    "                                    --data_root_dir <PATH/TO/RLDS/DATASETS/DIRECTORY> \\\n",
    "                                    --dataset_name <DATASET_NAME> \\\n",
    "                                    --run_root_dir <PATH/TO/LOGS/DIR> \\\n",
    "                                    ...\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import draccus\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import tqdm\n",
    "from accelerate import PartialState\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor, BitsAndBytesConfig\n",
    "from transformers import AutoConfig, AutoImageProcessor\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "\n",
    "import wandb\n",
    "from prismatic.models.backbones.llm.prompting import PurePromptBuilder, VicunaV15ChatPromptBuilder\n",
    "from prismatic.util.data_utils import PaddedCollatorForActionPrediction\n",
    "from prismatic.vla.action_tokenizer import ActionTokenizer\n",
    "from prismatic.vla.datasets import RLDSBatchTransform, RLDSDataset\n",
    "from prismatic.vla.datasets.rlds.utils.data_utils import save_dataset_statistics\n",
    "\n",
    "from prismatic.extern.hf.configuration_prismatic import OpenVLAConfig\n",
    "from prismatic.extern.hf.modeling_prismatic import OpenVLAForActionPrediction\n",
    "from prismatic.extern.hf.processing_prismatic import PrismaticImageProcessor, PrismaticProcessor\n",
    "\n",
    "# Sane Defaults\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bbd863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FinetuneConfig:\n",
    "    # fmt: off\n",
    "    vla_path: str = \"/home/chuangzhi/zhq/yjc/runs/3-2+b2+lr-4e-06+lora-r32-steps10000\"                            # Path to OpenVLA model (on HuggingFace Hub)\n",
    "\n",
    "    # Directory Paths\n",
    "    data_root_dir: Path = Path(\"/home/chuangzhi/zhq/yjc/mydata_tensorflow_datasets\")        # Path to Open-X dataset directory\n",
    "    dataset_name: str = \"example_dataset\"           # Name of fine-tuning dataset (e.g., `droid_wipe`)\n",
    "    # data_root_dir = '/home/chuangzhi/zhq/yjc/modified_libero_rlds'\n",
    "    # dataset_name = 'libero_spatial_no_noops'\n",
    "    run_root_dir: Path = Path(\"runs\")                               # Path to directory to store logs & checkpoints\n",
    "    adapter_tmp_dir: Path = Path(\"adapter-tmp\")                     # Temporary directory for LoRA weights before fusing\n",
    "\n",
    "    # Fine-tuning Parameters\n",
    "    batch_size: int = 1                                            # Fine-tuning batch size\n",
    "    max_steps: int = 200_000                                        # Max number of fine-tuning steps\n",
    "    save_steps: int = 5000                                          # Interval for checkpoint saving\n",
    "    learning_rate: float = 5e-4                                     # Fine-tuning learning rate\n",
    "    grad_accumulation_steps: int = 2                                # Gradient accumulation steps\n",
    "    image_aug: bool = True                                          # Whether to train with image augmentations\n",
    "    shuffle_buffer_size: int = 100_000                              # Dataloader shuffle buffer size (can reduce if OOM)\n",
    "    save_latest_checkpoint_only: bool = True                        # Whether to save only one checkpoint per run and\n",
    "                                                                    #   continually overwrite the latest checkpoint\n",
    "                                                                    #   (If False, saves all checkpoints)\n",
    "\n",
    "    # LoRA Arguments\n",
    "    use_lora: bool = True                                           # Whether to use LoRA fine-tuning\n",
    "    lora_rank: int = 32                                             # Rank of LoRA weight matrix\n",
    "    lora_dropout: float = 0.0                                       # Dropout applied to LoRA weights\n",
    "    use_quantization: bool = False                                  # Whether to 4-bit quantize VLA for LoRA fine-tuning\n",
    "                                                                    #   => CAUTION: Reduces memory but hurts performance\n",
    "\n",
    "    # Tracking Parameters\n",
    "    wandb_project: str = \"123\"                                  # Name of W&B project to log to (use default!)\n",
    "    wandb_entity: str = \"1275259847-tianjin-university\"                          # Name of entity to log under\n",
    "    run_id_note: Optional[str] = None                               # Extra note for logging, Weights & Biases\n",
    "\n",
    "    # fmt: on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3d2a79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinetuneConfig(vla_path='/home/chuangzhi/zhq/yjc/runs/3-2+b2+lr-4e-06+lora-r32-steps10000', data_root_dir=PosixPath('/home/chuangzhi/zhq/yjc/mydata_tensorflow_datasets'), dataset_name='example_dataset', run_root_dir=PosixPath('runs'), adapter_tmp_dir=PosixPath('adapter-tmp'), batch_size=1, max_steps=200000, save_steps=5000, learning_rate=0.0005, grad_accumulation_steps=2, image_aug=True, shuffle_buffer_size=100000, save_latest_checkpoint_only=True, use_lora=True, lora_rank=32, lora_dropout=0.0, use_quantization=False, wandb_project='123', wandb_entity='1275259847-tianjin-university', run_id_note=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = FinetuneConfig()\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96467429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.90it/s]\n",
      "2025-05-20 12:35:00.480938: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">05/20 [12:35:00] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt; <span style=\"font-weight: bold\">[</span>*<span style=\"font-weight: bold\">]</span> Loading existing dataset statistics from                       <a href=\"file:///home/chuangzhi/zhq/yjc/openvla/prismatic/vla/datasets/rlds/utils/data_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/chuangzhi/zhq/yjc/openvla/prismatic/vla/datasets/rlds/utils/data_utils.py#208\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">208</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/home/chuangzhi/zhq/yjc/mydata_tensorflow_datasets/example_dataset/1.0.</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         <span style=\"color: #800080; text-decoration-color: #800080\">0/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">dataset_statistics_62d7d87c8afd5d7abdea101ead77416d8996d92d5020c0ec9f</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">e7df53ab1ed90e.json.</span>                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m05/20 [12:35:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >> \u001b[1m[\u001b[0m*\u001b[1m]\u001b[0m Loading existing dataset statistics from                       \u001b]8;id=267821;file:///home/chuangzhi/zhq/yjc/openvla/prismatic/vla/datasets/rlds/utils/data_utils.py\u001b\\\u001b[2mdata_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=929487;file:///home/chuangzhi/zhq/yjc/openvla/prismatic/vla/datasets/rlds/utils/data_utils.py#208\u001b\\\u001b[2m208\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                 \u001b[0m         \u001b[35m/home/chuangzhi/zhq/yjc/mydata_tensorflow_datasets/example_dataset/1.0.\u001b[0m \u001b[2m                 \u001b[0m\n",
       "\u001b[2;36m                 \u001b[0m         \u001b[35m0/\u001b[0m\u001b[95mdataset_statistics_62d7d87c8afd5d7abdea101ead77416d8996d92d5020c0ec9f\u001b[0m \u001b[2m                 \u001b[0m\n",
       "\u001b[2;36m                 \u001b[0m         \u001b[95me7df53ab1ed90e.json.\u001b[0m                                                    \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 12:35:00.920937: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################################\n",
      "# Loading the following 1 datasets (incl. sampling weight):                         #\n",
      "# example_dataset: =========================================================1.000000 #\n",
      "######################################################################################\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">05/20 [12:35:01] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt; <span style=\"font-weight: bold\">[</span>*<span style=\"font-weight: bold\">]</span> Threads per Dataset: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>                                          <a href=\"file:///home/chuangzhi/zhq/yjc/openvla/prismatic/vla/datasets/rlds/dataset.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/chuangzhi/zhq/yjc/openvla/prismatic/vla/datasets/rlds/dataset.py#531\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">531</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m05/20 [12:35:01]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >> \u001b[1m[\u001b[0m*\u001b[1m]\u001b[0m Threads per Dataset: \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m                                          \u001b]8;id=360135;file:///home/chuangzhi/zhq/yjc/openvla/prismatic/vla/datasets/rlds/dataset.py\u001b\\\u001b[2mdataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=497205;file:///home/chuangzhi/zhq/yjc/openvla/prismatic/vla/datasets/rlds/dataset.py#531\u001b\\\u001b[2m531\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt; <span style=\"font-weight: bold\">[</span>*<span style=\"font-weight: bold\">]</span> Reads per Dataset: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>                                            <a href=\"file:///home/chuangzhi/zhq/yjc/openvla/prismatic/vla/datasets/rlds/dataset.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/chuangzhi/zhq/yjc/openvla/prismatic/vla/datasets/rlds/dataset.py#532\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">532</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >> \u001b[1m[\u001b[0m*\u001b[1m]\u001b[0m Reads per Dataset: \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m                                            \u001b]8;id=756268;file:///home/chuangzhi/zhq/yjc/openvla/prismatic/vla/datasets/rlds/dataset.py\u001b\\\u001b[2mdataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=4969;file:///home/chuangzhi/zhq/yjc/openvla/prismatic/vla/datasets/rlds/dataset.py#532\u001b\\\u001b[2m532\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt; <span style=\"font-weight: bold\">[</span>*<span style=\"font-weight: bold\">]</span> Constructing datasets<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                          <a href=\"file:///home/chuangzhi/zhq/yjc/openvla/prismatic/vla/datasets/rlds/dataset.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/chuangzhi/zhq/yjc/openvla/prismatic/vla/datasets/rlds/dataset.py#535\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">535</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >> \u001b[1m[\u001b[0m*\u001b[1m]\u001b[0m Constructing datasets\u001b[33m...\u001b[0m                                          \u001b]8;id=176313;file:///home/chuangzhi/zhq/yjc/openvla/prismatic/vla/datasets/rlds/dataset.py\u001b\\\u001b[2mdataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=582191;file:///home/chuangzhi/zhq/yjc/openvla/prismatic/vla/datasets/rlds/dataset.py#535\u001b\\\u001b[2m535\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 12:35:01.321489: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt; <span style=\"font-weight: bold\">[</span>*<span style=\"font-weight: bold\">]</span> Applying frame transforms on dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                           <a href=\"file:///home/chuangzhi/zhq/yjc/openvla/prismatic/vla/datasets/rlds/dataset.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/chuangzhi/zhq/yjc/openvla/prismatic/vla/datasets/rlds/dataset.py#575\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">575</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >> \u001b[1m[\u001b[0m*\u001b[1m]\u001b[0m Applying frame transforms on dataset\u001b[33m...\u001b[0m                           \u001b]8;id=577941;file:///home/chuangzhi/zhq/yjc/openvla/prismatic/vla/datasets/rlds/dataset.py\u001b\\\u001b[2mdataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=669538;file:///home/chuangzhi/zhq/yjc/openvla/prismatic/vla/datasets/rlds/dataset.py#575\u001b\\\u001b[2m575\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "distributed_state = PartialState()\n",
    "torch.cuda.set_device(device_id := distributed_state.local_process_index)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Quantization Config =>> only if LoRA fine-tuning\n",
    "quantization_config = None\n",
    "\n",
    "# Register OpenVLA model to HF Auto Classes (not needed if the model is on HF Hub)\n",
    "AutoConfig.register(\"openvla\", OpenVLAConfig)\n",
    "AutoImageProcessor.register(OpenVLAConfig, PrismaticImageProcessor)\n",
    "AutoProcessor.register(OpenVLAConfig, PrismaticProcessor)\n",
    "AutoModelForVision2Seq.register(OpenVLAConfig, OpenVLAForActionPrediction)\n",
    "\n",
    "# Load OpenVLA Processor and Model using HF AutoClasses\n",
    "processor = AutoProcessor.from_pretrained(cfg.vla_path, trust_remote_code=True)\n",
    "\n",
    "\n",
    "# Create Action Tokenizer\n",
    "action_tokenizer = ActionTokenizer(processor.tokenizer)\n",
    "\n",
    "batch_transform = RLDSBatchTransform(\n",
    "    action_tokenizer,\n",
    "    processor.tokenizer,\n",
    "    image_transform=processor.image_processor.apply_transform,\n",
    "    prompt_builder_fn=PurePromptBuilder if \"v01\" not in cfg.vla_path else VicunaV15ChatPromptBuilder,\n",
    ")\n",
    "vla = AutoModelForVision2Seq.from_pretrained(\n",
    "    cfg.vla_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=quantization_config,\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "vla = vla.to(device_id)\n",
    "vla_dataset = RLDSDataset(\n",
    "    cfg.data_root_dir,\n",
    "    cfg.dataset_name,\n",
    "    batch_transform,\n",
    "    resize_resolution=tuple(vla.config.image_sizes), #tuple(vla.module.config.image_sizes)\n",
    "    shuffle_buffer_size=cfg.shuffle_buffer_size,\n",
    "    image_aug=cfg.image_aug,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f5852fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create Collator and DataLoader\n",
    "collator = PaddedCollatorForActionPrediction(\n",
    "    processor.tokenizer.model_max_length, processor.tokenizer.pad_token_id, padding_side=\"right\"\n",
    ")\n",
    "dataloader = DataLoader(\n",
    "    vla_dataset,\n",
    "    batch_size=cfg.batch_size,\n",
    "    sampler=None,\n",
    "    collate_fn=collator,\n",
    "    num_workers=0,  # Important =>> Set to 0 if using RLDS; TFDS rolls its own parallelism!\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96144bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1747715707.168457 2529976 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -7 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2800 num_cores: 128 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 524288 l3_cache_size: 268435456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -8 } dim { size: -9 } dim { size: -7 } } }\n",
      "W0000 00:00:1747715707.168902 2529976 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -6 } } } inputs { dtype: DT_FLOAT shape { dim { size: -3 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -3 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2800 num_cores: 128 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 524288 l3_cache_size: 268435456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -3 } dim { size: -10 } dim { size: -11 } dim { size: -6 } } }\n"
     ]
    }
   ],
   "source": [
    "first_batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fe48115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pixel_values', 'input_ids', 'attention_mask', 'labels', 'dataset_names'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   512, 29901,  1724,  3158,   881,   278, 19964,  2125,   304,\n",
       "          4337,   278, 13748,   292, 12917,   304,   278, 25972, 29889, 29973,\n",
       "            13,  3744, 29901, 31988, 31842, 31872, 31903, 31853, 31830, 31872,\n",
       "             2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06e1077a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   512, 29901,  1724,  3158,   881,   278, 19964,  2125,   304,\n",
       "          4337,   278, 13748,   292, 12917,   304,   278, 25972, 29889, 29973,\n",
       "            13,  3744, 29901, 29871, 31872, 31899, 31872, 31843, 31837, 31824,\n",
       "         31744,     2]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cd0434c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    1,   512, 29901,  1724,  3158,   881,   278, 19964,  2125,   304,\n",
       "         4337,   278, 13748,   292, 12917,   304,   278, 25972, 29889, 29973,\n",
       "           13,  3744, 29901])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch['input_ids'][0][:-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72ec7771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> In: What action should the robot take to move the drinking glass to the basket.?\\nOut: '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.decode(first_batch['input_ids'][0][:-8].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9889076a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab5d27d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 224, 224])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bbbfd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c78c8ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100, 31872, 31922, 31872, 31801, 31859, 31851,\n",
       "         31872,     2]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4179cc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrismaticProcessor:\n",
       "- image_processor: PrismaticImageProcessor {\n",
       "  \"auto_map\": {\n",
       "    \"AutoImageProcessor\": \"processing_prismatic.PrismaticImageProcessor\",\n",
       "    \"AutoProcessor\": \"processing_prismatic.PrismaticProcessor\"\n",
       "  },\n",
       "  \"image_processor_type\": \"PrismaticImageProcessor\",\n",
       "  \"image_resize_strategy\": \"resize-naive\",\n",
       "  \"input_sizes\": [\n",
       "    [\n",
       "      3,\n",
       "      224,\n",
       "      224\n",
       "    ],\n",
       "    [\n",
       "      3,\n",
       "      224,\n",
       "      224\n",
       "    ]\n",
       "  ],\n",
       "  \"interpolations\": [\n",
       "    \"bicubic\",\n",
       "    \"bicubic\"\n",
       "  ],\n",
       "  \"means\": [\n",
       "    [\n",
       "      0.485,\n",
       "      0.456,\n",
       "      0.406\n",
       "    ],\n",
       "    [\n",
       "      0.5,\n",
       "      0.5,\n",
       "      0.5\n",
       "    ]\n",
       "  ],\n",
       "  \"processor_class\": \"PrismaticProcessor\",\n",
       "  \"stds\": [\n",
       "    [\n",
       "      0.229,\n",
       "      0.224,\n",
       "      0.225\n",
       "    ],\n",
       "    [\n",
       "      0.5,\n",
       "      0.5,\n",
       "      0.5\n",
       "    ]\n",
       "  ],\n",
       "  \"tvf_crop_params\": [\n",
       "    {\n",
       "      \"output_size\": [\n",
       "        224,\n",
       "        224\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"output_size\": [\n",
       "        224,\n",
       "        224\n",
       "      ]\n",
       "    }\n",
       "  ],\n",
       "  \"tvf_do_letterbox\": false,\n",
       "  \"tvf_letterbox_fill\": null,\n",
       "  \"tvf_normalize_params\": [\n",
       "    {\n",
       "      \"inplace\": false,\n",
       "      \"mean\": [\n",
       "        0.484375,\n",
       "        0.455078125,\n",
       "        0.40625\n",
       "      ],\n",
       "      \"std\": [\n",
       "        0.228515625,\n",
       "        0.2236328125,\n",
       "        0.224609375\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"inplace\": false,\n",
       "      \"mean\": [\n",
       "        0.5,\n",
       "        0.5,\n",
       "        0.5\n",
       "      ],\n",
       "      \"std\": [\n",
       "        0.5,\n",
       "        0.5,\n",
       "        0.5\n",
       "      ]\n",
       "    }\n",
       "  ],\n",
       "  \"tvf_resize_params\": [\n",
       "    {\n",
       "      \"antialias\": true,\n",
       "      \"interpolation\": 3,\n",
       "      \"max_size\": null,\n",
       "      \"size\": [\n",
       "        224,\n",
       "        224\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"antialias\": true,\n",
       "      \"interpolation\": 3,\n",
       "      \"max_size\": null,\n",
       "      \"size\": [\n",
       "        224,\n",
       "        224\n",
       "      ]\n",
       "    }\n",
       "  ],\n",
       "  \"use_fused_vision_backbone\": true\n",
       "}\n",
       "\n",
       "- tokenizer: LlamaTokenizerFast(name_or_path='/home/chuangzhi/zhq/yjc/runs/3-2+b2+lr-4e-06+lora-r32-steps10000', vocab_size=32000, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<PAD>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32000: AddedToken(\"<PAD>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       "\n",
       "{\n",
       "  \"processor_class\": \"PrismaticProcessor\"\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e03ce02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrismaticImageProcessor {\n",
       "  \"auto_map\": {\n",
       "    \"AutoImageProcessor\": \"processing_prismatic.PrismaticImageProcessor\",\n",
       "    \"AutoProcessor\": \"processing_prismatic.PrismaticProcessor\"\n",
       "  },\n",
       "  \"image_processor_type\": \"PrismaticImageProcessor\",\n",
       "  \"image_resize_strategy\": \"resize-naive\",\n",
       "  \"input_sizes\": [\n",
       "    [\n",
       "      3,\n",
       "      224,\n",
       "      224\n",
       "    ],\n",
       "    [\n",
       "      3,\n",
       "      224,\n",
       "      224\n",
       "    ]\n",
       "  ],\n",
       "  \"interpolations\": [\n",
       "    \"bicubic\",\n",
       "    \"bicubic\"\n",
       "  ],\n",
       "  \"means\": [\n",
       "    [\n",
       "      0.485,\n",
       "      0.456,\n",
       "      0.406\n",
       "    ],\n",
       "    [\n",
       "      0.5,\n",
       "      0.5,\n",
       "      0.5\n",
       "    ]\n",
       "  ],\n",
       "  \"processor_class\": \"PrismaticProcessor\",\n",
       "  \"stds\": [\n",
       "    [\n",
       "      0.229,\n",
       "      0.224,\n",
       "      0.225\n",
       "    ],\n",
       "    [\n",
       "      0.5,\n",
       "      0.5,\n",
       "      0.5\n",
       "    ]\n",
       "  ],\n",
       "  \"tvf_crop_params\": [\n",
       "    {\n",
       "      \"output_size\": [\n",
       "        224,\n",
       "        224\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"output_size\": [\n",
       "        224,\n",
       "        224\n",
       "      ]\n",
       "    }\n",
       "  ],\n",
       "  \"tvf_do_letterbox\": false,\n",
       "  \"tvf_letterbox_fill\": null,\n",
       "  \"tvf_normalize_params\": [\n",
       "    {\n",
       "      \"inplace\": false,\n",
       "      \"mean\": [\n",
       "        0.484375,\n",
       "        0.455078125,\n",
       "        0.40625\n",
       "      ],\n",
       "      \"std\": [\n",
       "        0.228515625,\n",
       "        0.2236328125,\n",
       "        0.224609375\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"inplace\": false,\n",
       "      \"mean\": [\n",
       "        0.5,\n",
       "        0.5,\n",
       "        0.5\n",
       "      ],\n",
       "      \"std\": [\n",
       "        0.5,\n",
       "        0.5,\n",
       "        0.5\n",
       "      ]\n",
       "    }\n",
       "  ],\n",
       "  \"tvf_resize_params\": [\n",
       "    {\n",
       "      \"antialias\": true,\n",
       "      \"interpolation\": 3,\n",
       "      \"max_size\": null,\n",
       "      \"size\": [\n",
       "        224,\n",
       "        224\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"antialias\": true,\n",
       "      \"interpolation\": 3,\n",
       "      \"max_size\": null,\n",
       "      \"size\": [\n",
       "        224,\n",
       "        224\n",
       "      ]\n",
       "    }\n",
       "  ],\n",
       "  \"use_fused_vision_backbone\": true\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88e48a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ActionTokenizer.decode_token_ids_to_actions of <prismatic.vla.action_tokenizer.ActionTokenizer object at 0x7f911a5da2c0>>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_tokenizer.decode_token_ids_to_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "017363d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31743"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_tokenizer.action_token_begin_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08881806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method OpenVLAForActionPrediction.predict_action of OpenVLAForActionPrediction(\n",
       "  (vision_backbone): PrismaticVisionBackbone(\n",
       "    (featurizer): VisionTransformer(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
       "        (norm): Identity()\n",
       "      )\n",
       "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "      (patch_drop): Identity()\n",
       "      (norm_pre): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (3): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (4): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (5): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (6): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (7): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (8): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (9): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (10): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (11): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (12): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (13): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (14): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (15): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (16): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (17): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (18): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (19): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (20): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (21): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (22): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (23): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (fc_norm): Identity()\n",
       "      (head_drop): Dropout(p=0.0, inplace=False)\n",
       "      (head): Identity()\n",
       "    )\n",
       "    (fused_featurizer): VisionTransformer(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14))\n",
       "        (norm): Identity()\n",
       "      )\n",
       "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "      (patch_drop): Identity()\n",
       "      (norm_pre): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (3): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (4): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (5): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (6): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (7): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (8): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (9): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (10): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (11): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (12): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (13): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (14): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (15): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (16): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (17): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (18): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (19): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (20): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (21): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (22): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (23): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (24): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (25): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (26): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn_pool): AttentionPoolLatent(\n",
       "        (q): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "        (kv): Linear(in_features=1152, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (fc_norm): Identity()\n",
       "      (head_drop): Dropout(p=0.0, inplace=False)\n",
       "      (head): Identity()\n",
       "    )\n",
       "  )\n",
       "  (projector): PrismaticProjector(\n",
       "    (fc1): Linear(in_features=2176, out_features=8704, bias=True)\n",
       "    (fc2): Linear(in_features=8704, out_features=4096, bias=True)\n",
       "    (fc3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (act_fn1): GELU(approximate='none')\n",
       "    (act_fn2): GELU(approximate='none')\n",
       "  )\n",
       "  (language_model): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(32064, 4096, padding_idx=32000)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaSdpaAttention(\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm()\n",
       "          (post_attention_layernorm): LlamaRMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vla.predict_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50ba47f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vla.train()\n",
    "# output: CausalLMOutputWithPast = vla(\n",
    "#     input_ids=first_batch[\"input_ids\"].to(device_id),\n",
    "#     attention_mask=first_batch[\"attention_mask\"].to(device_id),\n",
    "#     pixel_values=first_batch[\"pixel_values\"].to(torch.bfloat16).to(device_id),\n",
    "#     labels=first_batch[\"labels\"],\n",
    "# )\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pixel_values', 'input_ids', 'attention_mask', 'labels', 'dataset_names'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "459ecb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_builder_fn=PurePromptBuilder if \"v01\" not in cfg.vla_path else VicunaV15ChatPromptBuilder\n",
    "\n",
    "\n",
    "\n",
    "# Construct Chat-based Prompt =>> Input is default query + language instruction, output are the action tokens\n",
    "prompt_builder = prompt_builder_fn(\"openvla\")\n",
    "\n",
    "input_ids = processor.tokenizer(prompt_builder.get_prompt(), add_special_tokens=True).input_ids\n",
    "input_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87679a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3df318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dec14a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
